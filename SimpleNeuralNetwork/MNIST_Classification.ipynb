{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification with Feedforward Neural Network\n",
    "\n",
    "This notebook builds, trains, and evaluates a simple neural network to classify handwritten digits (0-9) from the MNIST dataset.\n",
    "\n",
    "**Framework:** TensorFlow/Keras\n",
    "\n",
    "**Estimated time to run:** 3-5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Import Libraries\n",
    "\n",
    "We start by importing the tools we need. Think of these as importing JavaScript libraries into a web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy for numerical operations (arrays, math)\n",
    "import numpy as np\n",
    "\n",
    "# Import Matplotlib for visualizing images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TensorFlow/Keras (deep learning framework)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Load and Explore the MNIST Dataset\n",
    "\n",
    "MNIST is already available in Keras, so we can load it with one line of code.\n",
    "\n",
    "The dataset contains 70,000 images of handwritten digits, each 28×28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "# Keras includes MNIST with train/test split already done\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Dataset loaded!\")\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  - Images shape: {train_images.shape}\")\n",
    "print(f\"    (60,000 images, each 28×28 pixels)\")\n",
    "print(f\"  - Labels shape: {train_labels.shape}\")\n",
    "print(f\"    (60,000 labels, values 0-9)\")\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  - Images shape: {test_images.shape}\")\n",
    "print(f\"    (10,000 images, each 28×28 pixels)\")\n",
    "print(f\"  - Labels shape: {test_labels.shape}\")\n",
    "\n",
    "print(f\"\\nPixel value range: {train_images.min()} - {train_images.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a single training image\n",
    "# This helps us understand what the data looks like\n",
    "\n",
    "sample_index = 0  # First image in training set\n",
    "sample_image = train_images[sample_index]\n",
    "sample_label = train_labels[sample_index]\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(sample_image, cmap='gray')  # 'gray' shows grayscale images\n",
    "plt.title(f\"Digit: {sample_label}\")\n",
    "plt.axis('off')  # Hide axis labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"This image represents the digit: {sample_label}\")\n",
    "print(f\"Image shape: {sample_image.shape} (28 pixels × 28 pixels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Data Preparation\n",
    "\n",
    "Before we can train the neural network, we need to prepare the data:\n",
    "1. **Normalize** pixel values (scale to 0-1)\n",
    "2. **Flatten** images (convert 28×28 to 784-length vector)\n",
    "3. **One-hot encode** labels (convert 3 to [0,0,0,1,0,0,0,0,0,0])\n",
    "\n",
    "See `GUIDE_1_Data_Preparation.md` for detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Normalize Pixel Values\n",
    "\n",
    "Pixel values range from 0-255. We divide by 255 to scale them to 0-1.\n",
    "\n",
    "**Why?** Neural networks learn better with smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize: divide all pixel values by 255\n",
    "# This converts range [0, 255] to [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "print(\"✓ Normalization complete\")\n",
    "print(f\"New pixel value range: {train_images.min():.4f} - {train_images.max():.4f}\")\n",
    "print(f\"Example pixel values: {train_images[0, 0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Flatten Images\n",
    "\n",
    "Neural networks expect 1D input (a vector), not 2D (a grid).\n",
    "\n",
    "We reshape each 28×28 image into a single vector of 784 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten: reshape 28x28 images into 784-length vectors\n",
    "# reshape(-1, 784) means: \"reshape to have 784 columns, auto-determine rows\"\n",
    "train_images_flat = train_images.reshape(-1, 784)\n",
    "test_images_flat = test_images.reshape(-1, 784)\n",
    "\n",
    "print(\"✓ Flattening complete\")\n",
    "print(f\"Original shape: (60000, 28, 28) - a 2D grid\")\n",
    "print(f\"New shape: {train_images_flat.shape} - a 1D vector\")\n",
    "print(f\"\\nTotal values per image: 28 × 28 = {28 * 28}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: One-Hot Encode Labels\n",
    "\n",
    "Instead of storing labels as single numbers (3, 5, 7),\n",
    "we convert them to vectors where only one position is 1 and others are 0.\n",
    "\n",
    "**Example:**\n",
    "- Label 3 → [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "- Label 5 → [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "# num_classes=10 because we have digits 0-9\n",
    "train_labels_encoded = to_categorical(train_labels, num_classes=10)\n",
    "test_labels_encoded = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "print(\"✓ One-hot encoding complete\")\n",
    "print(f\"Original labels shape: {train_labels.shape}\")\n",
    "print(f\"Encoded labels shape: {train_labels_encoded.shape}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"  Original label: {train_labels[0]}\")\n",
    "print(f\"  One-hot encoded: {train_labels_encoded[0]}\")\n",
    "print(f\"  (Position {np.argmax(train_labels_encoded[0])} has the 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Preparation Complete!\\n\")\n",
    "print(\"=\"*50)\n",
    "print(\"TRAINING DATA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Images: {train_images_flat.shape}\")\n",
    "print(f\"  - 60,000 images\")\n",
    "print(f\"  - Each is 784 values (28×28 flattened)\")\n",
    "print(f\"  - Values range: 0-1 (normalized)\")\n",
    "print(f\"\\nLabels: {train_labels_encoded.shape}\")\n",
    "print(f\"  - 60,000 labels\")\n",
    "print(f\"  - Each is 10 values (one-hot encoded)\")\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"TEST DATA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Images: {test_images_flat.shape}\")\n",
    "print(f\"Labels: {test_labels_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Build the Neural Network Model\n",
    "\n",
    "We create a Feedforward Neural Network (FNN) with:\n",
    "- **Input Layer:** 784 neurons (one per pixel)\n",
    "- **Hidden Layer 1:** 128 neurons with ReLU activation\n",
    "- **Hidden Layer 2:** 64 neurons with ReLU activation\n",
    "- **Output Layer:** 10 neurons with Softmax activation\n",
    "\n",
    "See `GUIDE_2_Model_Architecture.md` for detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model (layers stacked one after another)\n",
    "model = Sequential([\n",
    "    # Input layer + Hidden layer 1\n",
    "    # Dense = fully connected layer (each neuron connects to all previous neurons)\n",
    "    # input_shape=(784,) tells Keras to expect 784 input values\n",
    "    # ReLU activation: outputs max(0, input) - allows non-linear learning\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    # 64 neurons, ReLU activation\n",
    "    # Input is automatically (128,) from previous layer\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    # Output layer\n",
    "    # 10 neurons (one for each digit 0-9)\n",
    "    # Softmax activation: converts outputs to probabilities that sum to 1\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"✓ Model architecture created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ARCHITECTURE EXPLANATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nLayer 1 (Dense): 128 neurons\")\n",
    "print(f\"  Input: 784 values (flattened image)\")\n",
    "print(f\"  Parameters: 784×128 weights + 128 biases = 100,480\")\n",
    "print(f\"  Activation: ReLU (Rectified Linear Unit)\")\n",
    "print(f\"  Output: 128 values\")\n",
    "print(f\"\\nLayer 2 (Dense): 64 neurons\")\n",
    "print(f\"  Input: 128 values from Layer 1\")\n",
    "print(f\"  Parameters: 128×64 weights + 64 biases = 8,256\")\n",
    "print(f\"  Activation: ReLU\")\n",
    "print(f\"  Output: 64 values\")\n",
    "print(f\"\\nLayer 3 (Dense): 10 neurons\")\n",
    "print(f\"  Input: 64 values from Layer 2\")\n",
    "print(f\"  Parameters: 64×10 weights + 10 biases = 650\")\n",
    "print(f\"  Activation: Softmax (probability distribution)\")\n",
    "print(f\"  Output: 10 probabilities (sum = 1.0)\")\n",
    "print(f\"\\nTotal Parameters: 109,386\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Compile the Model\n",
    "\n",
    "Compilation tells Keras:\n",
    "- **Loss function:** How to measure error (Categorical Cross-Entropy)\n",
    "- **Optimizer:** How to improve weights (Adam)\n",
    "- **Metrics:** What to report (Accuracy)\n",
    "\n",
    "See `GUIDE_3_Training.md` for detailed explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # For multi-class classification\n",
    "    optimizer='adam',                 # Adaptive learning rate optimizer\n",
    "    metrics=['accuracy']              # Report accuracy during training\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled!\")\n",
    "print(\"\\nCompilation settings:\")\n",
    "print(f\"  Loss function: Categorical Cross-Entropy\")\n",
    "print(f\"  Optimizer: Adam\")\n",
    "print(f\"  Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Train the Model\n",
    "\n",
    "We train for 10 epochs (10 complete passes through all training data).\n",
    "\n",
    "During training:\n",
    "- Network makes predictions\n",
    "- Calculates error (loss)\n",
    "- Adjusts weights to reduce error\n",
    "- Repeats thousands of times\n",
    "\n",
    "You should see loss decreasing and accuracy increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# This is where the network learns!\n",
    "history = model.fit(\n",
    "    train_images_flat,        # Input: training images\n",
    "    train_labels_encoded,     # Output: training labels (one-hot encoded)\n",
    "    epochs=10,                # Number of times to go through all data\n",
    "    batch_size=32,            # Process 32 images before updating weights\n",
    "    validation_split=0.1,     # Use 10% of training data to validate\n",
    "    verbose=1                 # Show progress bar\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation metrics\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Loss over epochs\n",
    "ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Loss Over Training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy over epochs\n",
    "ax2.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy Over Training')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"  Initial Loss: {history.history['loss'][0]:.4f}\")\n",
    "print(f\"  Final Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"\\n  Initial Accuracy: {history.history['accuracy'][0]*100:.2f}%\")\n",
    "print(f\"  Final Accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"\\nValidation Accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Evaluate on Test Set\n",
    "\n",
    "Now we test the model on completely new data (test set).\n",
    "This shows how well the model generalizes to unseen images.\n",
    "\n",
    "See `GUIDE_4_Evaluation.md` for detailed explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# The network has never seen these images before!\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_images_flat,\n",
    "    test_labels_encoded,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"\\nCorrect Predictions: {int(test_accuracy * len(test_labels))} / {len(test_labels)}\")\n",
    "print(f\"Wrong Predictions: {len(test_labels) - int(test_accuracy * len(test_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Make Predictions on Individual Images\n",
    "\n",
    "Let's test the model on some specific images from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Single Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random test image\n",
    "random_index = np.random.randint(0, len(test_images_flat))\n",
    "test_image = test_images_flat[random_index]\n",
    "test_label = test_labels[random_index]\n",
    "\n",
    "# Make prediction\n",
    "# model.predict expects batch format, so reshape to (1, 784)\n",
    "prediction = model.predict(test_image.reshape(1, -1), verbose=0)\n",
    "\n",
    "# Extract results\n",
    "predicted_digit = np.argmax(prediction[0])  # Index of highest probability\n",
    "confidence = prediction[0][predicted_digit]  # Probability of predicted digit\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTest Case 1: Random Image\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"\\nTrue Label: {test_label}\")\n",
    "print(f\"Predicted Label: {predicted_digit}\")\n",
    "print(f\"Confidence: {confidence*100:.2f}%\")\n",
    "print(f\"Result: {'✓ CORRECT' if predicted_digit == test_label else '✗ WRONG'}\")\n",
    "\n",
    "# Show probability distribution\n",
    "print(f\"\\nProbabilities for each digit:\")\n",
    "for digit in range(10):\n",
    "    probability = prediction[0][digit]\n",
    "    bar_length = int(probability * 40)  # Scale for display\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"  {digit}: {bar} {probability*100:6.2f}%\")\n",
    "\n",
    "# Show the image\n",
    "image = test_images[random_index]\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"True: {test_label}, Predicted: {predicted_digit}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Different Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try another random image to see another example\n",
    "random_index_2 = np.random.randint(0, len(test_images_flat))\n",
    "test_image_2 = test_images_flat[random_index_2]\n",
    "test_label_2 = test_labels[random_index_2]\n",
    "\n",
    "# Make prediction\n",
    "prediction_2 = model.predict(test_image_2.reshape(1, -1), verbose=0)\n",
    "\n",
    "# Extract results\n",
    "predicted_digit_2 = np.argmax(prediction_2[0])\n",
    "confidence_2 = prediction_2[0][predicted_digit_2]\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nTest Case 2: Another Random Image\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"\\nTrue Label: {test_label_2}\")\n",
    "print(f\"Predicted Label: {predicted_digit_2}\")\n",
    "print(f\"Confidence: {confidence_2*100:.2f}%\")\n",
    "print(f\"Result: {'✓ CORRECT' if predicted_digit_2 == test_label_2 else '✗ WRONG'}\")\n",
    "\n",
    "# Show probability distribution\n",
    "print(f\"\\nProbabilities for each digit:\")\n",
    "for digit in range(10):\n",
    "    probability = prediction_2[0][digit]\n",
    "    bar_length = int(probability * 40)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"  {digit}: {bar} {probability*100:6.2f}%\")\n",
    "\n",
    "# Show the image\n",
    "image_2 = test_images[random_index_2]\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image_2, cmap='gray')\n",
    "plt.title(f\"True: {test_label_2}, Predicted: {predicted_digit_2}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Detailed Analysis\n",
    "\n",
    "Let's analyze the model's performance in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on all test images\n",
    "all_predictions = model.predict(test_images_flat, verbose=0)\n",
    "\n",
    "# Convert to digit predictions\n",
    "predicted_digits = np.argmax(all_predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy by digit\n",
    "print(\"\\nAccuracy by Digit:\")\n",
    "print(\"=\"*50)\n",
    "for digit in range(10):\n",
    "    # Find all test images of this digit\n",
    "    digit_mask = (test_labels == digit)\n",
    "    \n",
    "    # Calculate accuracy for this digit\n",
    "    digit_predictions = predicted_digits[digit_mask]\n",
    "    digit_true_labels = test_labels[digit_mask]\n",
    "    \n",
    "    accuracy = np.sum(digit_predictions == digit_true_labels) / len(digit_true_labels)\n",
    "    \n",
    "    # Show result with bar chart\n",
    "    bar_length = int(accuracy * 30)\n",
    "    bar = '█' * bar_length\n",
    "    print(f\"Digit {digit}: {bar} {accuracy*100:6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Easy and Hard Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find high-confidence correct predictions (easy cases)\n",
    "correct_mask = (predicted_digits == test_labels)\n",
    "confidences = np.max(all_predictions, axis=1)\n",
    "\n",
    "# Find easiest examples\n",
    "correct_indices = np.where(correct_mask)[0]\n",
    "if len(correct_indices) > 0:\n",
    "    easy_idx = correct_indices[np.argsort(-confidences[correct_indices])[:3]]\n",
    "else:\n",
    "    easy_idx = []\n",
    "\n",
    "# Find hardest examples (low confidence wrong predictions)\n",
    "wrong_mask = ~correct_mask\n",
    "wrong_indices = np.where(wrong_mask)[0]\n",
    "if len(wrong_indices) > 0:\n",
    "    hard_idx = wrong_indices[np.argsort(confidences[wrong_indices])[:3]]\n",
    "else:\n",
    "    hard_idx = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EASY EXAMPLES (High Confidence Correct)\")\n",
    "print(\"=\"*60)\n",
    "if len(easy_idx) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    for i, idx in enumerate(easy_idx):\n",
    "        image = test_images[idx]\n",
    "        true_digit = test_labels[idx]\n",
    "        pred_digit = predicted_digits[idx]\n",
    "        conf = confidences[idx]\n",
    "        \n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f\"True: {true_digit}, Pred: {pred_digit}\\nConf: {conf*100:.1f}%\")\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"No correct predictions found.\")\n",
    "\nprint(\"\\n\" + \"=\"*60)\nprint(\"HARD EXAMPLES (Wrong Predictions)\")\nprint(\"=\"*60)\nif len(hard_idx) > 0:\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    for i, idx in enumerate(hard_idx):\n        image = test_images[idx]\n        true_digit = test_labels[idx]\n        pred_digit = predicted_digits[idx]\n        conf = confidences[idx]\n        \n        axes[i].imshow(image, cmap='gray')\n        axes[i].set_title(f\"True: {true_digit}, Pred: {pred_digit}\\nConf: {conf*100:.1f}%\", \n                         color='red')\n        axes[i].axis('off')\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Perfect accuracy! No wrong predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've successfully built, trained, and evaluated a neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nMODEL ARCHITECTURE:\")\n",
    "print(f\"  - Input Layer: 784 neurons (28×28 pixels)\")\n",
    "print(f\"  - Hidden Layer 1: 128 neurons (ReLU)\")\n",
    "print(f\"  - Hidden Layer 2: 64 neurons (ReLU)\")\n",
    "print(f\"  - Output Layer: 10 neurons (Softmax)\")\n",
    "print(f\"\\nTRAINING:\")\n",
    "print(f\"  - Epochs: 10\")\n",
    "print(f\"  - Batch Size: 32\")\n",
    "print(f\"  - Loss Function: Categorical Cross-Entropy\")\n",
    "print(f\"  - Optimizer: Adam\")\n",
    "print(f\"\\nPERFORMANCE:\")\n",
    "print(f\"  - Training Accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  - Validation Accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  - Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"  - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"\\nRESULTS:\")\n",
    "print(f\"  - Correctly classified: {int(test_accuracy * len(test_labels))} / {len(test_labels)} images\")\n",
    "print(f\"  - Error rate: {(1 - test_accuracy)*100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"You have successfully completed the assignment!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
