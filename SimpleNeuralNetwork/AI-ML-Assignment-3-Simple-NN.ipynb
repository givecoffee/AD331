{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification - Complete Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\nmnist = keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nprint(f\"Training set shape: {x_train.shape}\")\nprint(f\"Test set shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to 0-1 range\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\nprint(f\"Normalized - pixel range: [{x_train.min()}, {x_train.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten 28x28 images to 784-dimensional vectors\nx_train_flat = x_train.reshape(-1, 28*28)\nx_test_flat = x_test.reshape(-1, 28*28)\n\nprint(f\"Flattened training shape: {x_train_flat.shape}\")\nprint(f\"Flattened test shape: {x_test_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\ny_train_encoded = keras.utils.to_categorical(y_train, 10)\ny_test_encoded = keras.utils.to_categorical(y_test, 10)\n\nprint(f\"Encoded training labels shape: {y_train_encoded.shape}\")\nprint(f\"Example - Label {y_train[0]} encoded as: {y_train_encoded[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Feedforward Neural Network\nmodel = keras.Sequential([\n    layers.Input(shape=(784,)),  # Input layer: 784 neurons\n    layers.Dense(128, activation='relu'),  # Hidden layer 1: 128 neurons, ReLU\n    layers.Dense(64, activation='relu'),   # Hidden layer 2: 64 neurons, ReLU\n    layers.Dense(10, activation='softmax')  # Output layer: 10 neurons, Softmax\n])\n\nmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with loss function, optimizer, and metrics\nmodel.compile(\n    loss='categorical_crossentropy',  # Loss function for multi-class classification\n    optimizer='adam',                 # Optimizer\n    metrics=['accuracy']              # Metrics to track\n)\n\nprint(\"Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\nhistory = model.fit(\n    x_train_flat,\n    y_train_encoded,\n    epochs=10,\n    batch_size=32,\n    validation_split=0.1,\n    verbose=1\n)\n\nprint(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\ntest_loss, test_accuracy = model.evaluate(x_test_flat, y_test_encoded, verbose=0)\n\nprint(\"=\"*50)\nprint(\"TEST SET PERFORMANCE\")\nprint(\"=\"*50)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\nprint(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\nplt.figure(figsize=(12, 4))\n\n# Plot accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample images\nplt.figure(figsize=(15, 3))\n\nfor i in range(10):\n    # Make prediction\n    prediction = model.predict(x_test_flat[i:i+1], verbose=0)\n    predicted_class = np.argmax(prediction[0])\n    true_class = y_test[i]\n    \n    # Plot\n    plt.subplot(2, 5, i+1)\n    plt.imshow(x_test[i], cmap='gray')\n    \n    color = 'green' if predicted_class == true_class else 'red'\n    plt.title(f'True: {true_class}, Pred: {predicted_class}', color=color)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\nprint(\"MNIST ASSIGNMENT COMPLETE\")\nprint(\"=\"*60)\nprint(f\"\\nModel Architecture:\")\nprint(f\"  - Input: 784 neurons (28x28 flattened images)\")\nprint(f\"  - Hidden Layer 1: 128 neurons (ReLU)\")\nprint(f\"  - Hidden Layer 2: 64 neurons (ReLU)\")\nprint(f\"  - Output: 10 neurons (Softmax)\")\nprint(f\"\\nTraining Details:\")\nprint(f\"  - Loss Function: Categorical Cross-Entropy\")\nprint(f\"  - Optimizer: Adam\")\nprint(f\"  - Epochs: 10\")\nprint(f\"  - Batch Size: 32\")\nprint(f\"\\nResults:\")\nprint(f\"  - Test Accuracy: {test_accuracy*100:.2f}%\")\nprint(f\"  - Test Loss: {test_loss:.4f}\")\nprint(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
